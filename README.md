# ğŸ¤ Talk-to-Me Claude CLI

> **Voice narration layer for Claude Code CLI** - Explains WHAT was done, not what's on screen

Like a lecturer explaining concepts rather than reading slides, this tool adds intelligent voice narration to Claude Code CLI that summarizes high-level changes instead of reading code line-by-line.

---

## ğŸ¯ The Problem

Standard text-to-speech for coding tasks is terrible:
- âŒ Reads file paths aloud
- âŒ Spells out code character by character
- âŒ Narrates tool usage ("I used the Edit tool...")
- âŒ Overwhelming for users

## âœ… The Solution

**Dual-output system:**
- **Screen** (Terminal): Shows code, diffs, file changes, errors
- **Voice** (Audio): High-level summary of what was accomplished

**Example:**

**Terminal:**
```
Editing src/auth/login.py...
  + Added email validation (lines 23-28)
  + Updated error handling (line 45)

Editing tests/test_login.py...
  + Added test_invalid_email (lines 67-72)
```

**Voice:**
> "I've strengthened the login system by adding email validation and improving
> the error messages users will see when something goes wrong. I also added
> tests to ensure the validation catches invalid email formats."

---

## ğŸš€ Quick Start

### 1. Install

```bash
# Clone the repository
git clone https://github.com/yourusername/talk-to-me-claude-cli.git
cd talk-to-me-claude-cli

# Install dependencies
pip install -r requirements.txt

# Or using the package
pip install -e .
```

### 2. Configure

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your OpenAI API key
# OPENAI_API_KEY=your-key-here
```

### 3. Run

```bash
# Check configuration
python -m src.wrapper --check

# Run in voice mode (demo)
python -m src.wrapper --voice

# Or use the installed command
talk-to-claude --voice
```

---

## ğŸ“‹ Features

### âœ… Phase 1 (Current - MVP)

- [x] Custom prompts with narration tags
- [x] Narration extraction from Claude's output
- [x] OpenAI TTS for voice output
- [x] OpenAI Whisper for voice input
- [x] Configurable verbosity (brief, medium, detailed)
- [x] Local TTS fallback (pyttsx3)

### ğŸš§ Phase 2 (Coming Soon)

- [ ] Actual Claude Code CLI integration
- [ ] MCP server implementation
- [ ] Provider fallback chain
- [ ] PTT (Push-to-Talk) support
- [ ] Session summaries

### ğŸ”® Phase 3 (Future)

- [ ] Multiple voice profiles
- [ ] Voice interruption handling
- [ ] Local Whisper support
- [ ] Custom vocabulary/pronunciation
- [ ] Multi-language support

---

## ğŸ›ï¸ Configuration

Edit `.env` to customize:

```bash
# Voice Providers
TTS_PROVIDER=openai        # openai or local
TTS_VOICE=nova            # alloy, echo, fable, nova, onyx, shimmer
TTS_SPEED=1.0             # 0.25 to 4.0

STT_PROVIDER=openai        # openai or local
STT_MODEL=whisper-1

# Narration Settings
NARRATION_ENABLED=true
NARRATION_VERBOSITY=medium  # brief, medium, detailed
AUTO_SPEAK=true            # Auto-play narration
```

---

## ğŸ’¡ How It Works

### Architecture

```
User (voice) â†’ STT â†’ Claude Code (with custom prompt)
                            â†“
                 Output with <voice_narration> tags
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                â†“
               Terminal          TTS (speak summary)
              (code/details)
```

### Narration Prompt

Claude receives a special system prompt instructing it to wrap summaries in `<voice_narration>` tags:

```xml
<voice_narration>
High-level summary of what was accomplished...
</voice_narration>

[Regular detailed output continues...]
```

The wrapper:
1. Extracts narration from tags
2. Displays regular output in terminal
3. Speaks the narration via TTS

---

## ğŸ“– Usage Examples

### Voice Mode

```bash
python -m src.wrapper --voice
```

Press Enter to record â†’ Speak your command â†’ Press Enter to stop â†’ Claude processes and narrates

### Text Mode (Demo)

```bash
python -m src.wrapper --text "Add error handling to the API"
```

### Show Narration Prompt

```bash
python -m src.wrapper --show-prompt
```

### Check Configuration

```bash
python -m src.wrapper --check
```

---

## ğŸ”§ Development

### Project Structure

```
talk-to-me-claude-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ wrapper.py       # Main CLI entry point
â”‚   â”œâ”€â”€ prompt.py        # Narration system prompts
â”‚   â”œâ”€â”€ extractor.py     # Extract <voice_narration> tags
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ tts.py       # Text-to-Speech providers
â”‚       â””â”€â”€ stt.py       # Speech-to-Text providers
â”œâ”€â”€ .env.example         # Configuration template
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ pyproject.toml       # Package configuration
â””â”€â”€ README.md
```

### Running Tests

```bash
# Test narration extraction
python -m src.extractor

# Test TTS
python -m src.voice.tts

# Test STT
python -m src.voice.stt
```

---

## ğŸ¤ Contributing

Contributions welcome! Areas that need help:

- [ ] Claude Code CLI integration
- [ ] MCP server implementation
- [ ] Local Whisper support
- [ ] Better VAD (Voice Activity Detection)
- [ ] Documentation improvements

---

## ğŸ“š Technical Background

This project was built based on research into:

- **Bumba-Voice** - MCP voice integration pattern
- **LiveWhisper** - Real-time STT with VAD
- **ALTS** - Local voice assistant architecture
- **SuperClaude** - Code summarization patterns

See [RESEARCH.md](.octocode/research/voice-integration/research.md) for full research findings.

---

## ğŸ“ Design Philosophy

**Key Principle:** Like a lecturer explaining slides, not reading them.

âŒ **Bad (Reading Output):**
> "Editing source slash auth slash login dot pie why... line twenty-three... added email at rate..."

âœ… **Good (Explaining Concepts):**
> "I've strengthened the login system by adding email validation and improving error messages."

---

## ğŸ› Troubleshooting

### No Audio Output

```bash
# Install audio libraries
pip install sounddevice soundfile numpy

# Test audio
python -c "import sounddevice as sd; sd.play([0.1]*10000, 44100); sd.wait()"
```

### OpenAI API Errors

```bash
# Check API key
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('OPENAI_API_KEY')[:10])"

# Test OpenAI connection
python -m src.voice.tts
```

### Import Errors

```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

---

## ğŸ™ Acknowledgments

- **Bumba-Voice** - MCP integration patterns
- **OpenAI** - Whisper and TTS APIs
- **Claude Code CLI** - The amazing tool we're enhancing

---

## ğŸ”— Links

- [Report Issues](https://github.com/yourusername/talk-to-me-claude-cli/issues)
- [Research Documentation](.octocode/research/voice-integration/research.md)
- [Claude Code](https://claude.ai/code)

---

**Built with â¤ï¸ for better developer experience**
